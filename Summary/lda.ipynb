{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5fLb62K-nds6"
   },
   "source": [
    "## step 1: read in data and extract pos/neg reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "RAXHxAFQ3RWm",
    "outputId": "c3b18866-295f-4cac-de1c-d930159ef85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pp5o2-h-lCiZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BcFwvi4SlHY7"
   },
   "outputs": [],
   "source": [
    "data_toy = pd.read_csv('/content/drive/My Drive/american_traditional_review.csv',nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S7BQsrXllr5n"
   },
   "outputs": [],
   "source": [
    "data_pos = data_toy['text'][data_toy['stars'] >= 4.0]\n",
    "data_neg = data_toy['text'][data_toy['stars'] <= 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bifiUZgcmU8G"
   },
   "outputs": [],
   "source": [
    "corpus_pos = list(data_pos)\n",
    "corpus_neg = list(data_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JB6EECCEnktl"
   },
   "source": [
    "## step 2: data preprocessing\n",
    "\n",
    "*   ### tokenization\n",
    "*   ### stopwords\n",
    "*   ### lemmatized\n",
    "*   ### stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qndf9CnKnj3k"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WRM9t66qncVJ",
    "outputId": "c4b886e7-ec6b-44d2-8b3f-ae8066a9d291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jf0lYIsNpvFO"
   },
   "source": [
    "### lemmatize eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C9p6HB3ypkzs",
    "outputId": "1a63774c-30d9-42c2-9438-fbebf60eddd7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy\n"
     ]
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('bought', pos = 'v')) # past tense to present tense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9U5B0w89p1PM"
   },
   "source": [
    "### stemmer eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "colab_type": "code",
    "id": "xHIqFyPnppDC",
    "outputId": "3cb8b138-1c3e-437f-85d4-4fa32872decc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original word</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caresses</td>\n",
       "      <td>caress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>flies</td>\n",
       "      <td>fli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dies</td>\n",
       "      <td>die</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>itemization</td>\n",
       "      <td>item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sensational</td>\n",
       "      <td>sensat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>traditional</td>\n",
       "      <td>tradit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>reference</td>\n",
       "      <td>refer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>colonizer</td>\n",
       "      <td>colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>plotted</td>\n",
       "      <td>plot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original word stemmed\n",
       "0      caresses  caress\n",
       "1         flies     fli\n",
       "2          dies     die\n",
       "3   itemization    item\n",
       "4   sensational  sensat\n",
       "5   traditional  tradit\n",
       "6     reference   refer\n",
       "7     colonizer   colon\n",
       "8       plotted    plot"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "original_words = ['caresses', 'flies', 'dies', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "\n",
    "pd.DataFrame(data={'original word':original_words, 'stemmed':singles })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vh2h8NJcqHOF"
   },
   "source": [
    "### wrap all transformation into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ca9e3pLTp7xf"
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "  result = []\n",
    "  for token in gensim.utils.simple_preprocess(text):\n",
    "    if token not in gensim.parsing.preprocessing.STOPWORDS:\n",
    "      token = stemmer.stem(WordNetLemmatizer().lemmatize(token, pos='v'))\n",
    "      result.append(token)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "qv8KpSuqqovY",
    "outputId": "669e5664-b544-4208-e3fb-822cf13169e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original document: \n",
      "['I', 'was', 'told', 'so', 'many', 'great', 'things', 'about', 'this', 'place', 'but', 'my', 'entire', 'experience', 'was', 'awful.']\n",
      "\n",
      "\n",
      "Tokenized and lemmatized document: \n",
      "['tell', 'great', 'thing', 'place', 'entir', 'experi', 'aw']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = \"I was told so many great things about this place but my entire experience was awful.\"\n",
    "\n",
    "print(\"Original document: \")\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print(\"\\n\\nTokenized and lemmatized document: \")\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T1GD7tVerK3g"
   },
   "outputs": [],
   "source": [
    "processed_pos = []\n",
    "for doc in corpus_pos:\n",
    "    processed_pos.append(preprocess(doc))\n",
    "    \n",
    "processed_neg = []\n",
    "for doc in corpus_neg:\n",
    "    processed_neg.append(preprocess(doc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n7RtZaUir2m9"
   },
   "source": [
    "## step 3: bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "37nnnKtnrqlj",
    "outputId": "51d15d65-4e1a-4677-b6a8-83fc5c0451ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 avoid\n",
      "1 bar\n",
      "2 belief\n",
      "3 best\n",
      "4 breakfast\n",
      "5 buffet\n",
      "6 chewi\n",
      "7 chimichurri\n",
      "8 chocol\n",
      "9 cold\n",
      "10 cooki\n"
     ]
    }
   ],
   "source": [
    "dict_pos = gensim.corpora.Dictionary(processed_pos)\n",
    "\n",
    "count = 0\n",
    "for k, v in dict_pos.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r8MHhpiOs9cZ"
   },
   "outputs": [],
   "source": [
    "bow_corpus = [dict_pos.doc2bow(doc) for doc in processed_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "01qm4bJ-tHgm",
    "outputId": "d682e77d-e3cd-4e65-9e3a-184d22e6142c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 4 (\"breakfast\") appears 1 time.\n",
      "Word 27 (\"good\") appears 2 time.\n",
      "Word 77 (\"servic\") appears 1 time.\n",
      "Word 186 (\"kid\") appears 1 time.\n",
      "Word 233 (\"awesom\") appears 1 time.\n",
      "Word 234 (\"benedict\") appears 2 time.\n",
      "Word 249 (\"price\") appears 1 time.\n",
      "Word 269 (\"love\") appears 1 time.\n",
      "Word 293 (\"friend\") appears 1 time.\n",
      "Word 640 (\"wow\") appears 1 time.\n",
      "Word 791 (\"approv\") appears 1 time.\n",
      "Word 792 (\"fact\") appears 1 time.\n",
      "Word 793 (\"florentin\") appears 1 time.\n",
      "Word 794 (\"mom\") appears 1 time.\n",
      "Word 795 (\"rubin\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "document_num = 50\n",
    "bow_doc_x = bow_corpus[document_num]\n",
    "\n",
    "for i in range(len(bow_doc_x)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_x[i][0], \n",
    "                                                     dict_pos[bow_doc_x[i][0]], \n",
    "                                                     bow_doc_x[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rQxu5gCwt3D1"
   },
   "source": [
    "## running LDA using bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IjlpIlHpt2re"
   },
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 5, \n",
    "                                   id2word = dict_pos,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "colab_type": "code",
    "id": "Tfgf8CvytlZz",
    "outputId": "88788bff-ed1f-484c-c27b-5dbe1d8f6589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.021*\"good\" + 0.018*\"food\" + 0.017*\"great\" + 0.011*\"servic\" + 0.010*\"place\" + 0.009*\"come\" + 0.009*\"like\" + 0.007*\"best\" + 0.006*\"get\" + 0.006*\"delici\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.010*\"place\" + 0.009*\"like\" + 0.009*\"food\" + 0.009*\"come\" + 0.009*\"time\" + 0.008*\"good\" + 0.007*\"ve\" + 0.007*\"love\" + 0.007*\"best\" + 0.006*\"tri\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.020*\"great\" + 0.020*\"food\" + 0.016*\"place\" + 0.013*\"good\" + 0.012*\"time\" + 0.011*\"servic\" + 0.011*\"breakfast\" + 0.009*\"love\" + 0.009*\"come\" + 0.009*\"like\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.028*\"place\" + 0.013*\"great\" + 0.012*\"food\" + 0.011*\"good\" + 0.009*\"love\" + 0.007*\"price\" + 0.007*\"like\" + 0.007*\"time\" + 0.006*\"get\" + 0.005*\"eat\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.014*\"food\" + 0.012*\"order\" + 0.011*\"great\" + 0.010*\"friend\" + 0.010*\"drink\" + 0.010*\"dog\" + 0.010*\"good\" + 0.009*\"servic\" + 0.009*\"come\" + 0.007*\"restaur\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "lda.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
